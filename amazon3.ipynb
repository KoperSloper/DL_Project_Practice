{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "dataset = Amazon(root='/tmp/Amazon', name='Computers', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: AmazonComputers():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 767\n",
      "Number of classes: 10\n",
      "\n",
      "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])\n",
      "===========================================================================================================\n",
      "Number of nodes: 13752\n",
      "Number of edges: 491722\n",
      "Average node degree: 35.76\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True,  ..., True, True, True])\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "transform = RandomNodeSplit(split = \"random\", num_train_per_class=1250, num_val = 0.10, num_test = 0.30)\n",
    "data = transform(data)\n",
    "\n",
    "print(data.train_mask)\n",
    "print(data.val_mask)\n",
    "print(data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.1586, Val Acc: 0.0269, Test Acc: 0.0291\n",
      "Epoch: 002, Train: 0.1588, Val Acc: 0.0276, Test Acc: 0.0291\n",
      "Epoch: 003, Train: 0.1587, Val Acc: 0.0276, Test Acc: 0.0291\n",
      "Epoch: 004, Train: 0.1588, Val Acc: 0.0269, Test Acc: 0.0293\n",
      "Epoch: 005, Train: 0.1592, Val Acc: 0.0269, Test Acc: 0.0296\n",
      "Epoch: 006, Train: 0.1711, Val Acc: 0.0342, Test Acc: 0.0388\n",
      "Epoch: 007, Train: 0.2440, Val Acc: 0.0938, Test Acc: 0.1100\n",
      "Epoch: 008, Train: 0.2950, Val Acc: 0.1542, Test Acc: 0.1592\n",
      "Epoch: 009, Train: 0.3734, Val Acc: 0.3287, Test Acc: 0.3272\n",
      "Epoch: 010, Train: 0.5425, Val Acc: 0.7207, Test Acc: 0.7172\n",
      "Epoch: 011, Train: 0.6080, Val Acc: 0.7935, Test Acc: 0.8005\n",
      "Epoch: 012, Train: 0.6487, Val Acc: 0.8116, Test Acc: 0.8306\n",
      "Epoch: 013, Train: 0.6972, Val Acc: 0.8473, Test Acc: 0.8674\n",
      "Epoch: 014, Train: 0.7548, Val Acc: 0.8596, Test Acc: 0.8805\n",
      "Epoch: 015, Train: 0.8079, Val Acc: 0.8669, Test Acc: 0.8873\n",
      "Epoch: 016, Train: 0.8419, Val Acc: 0.8742, Test Acc: 0.8941\n",
      "Epoch: 017, Train: 0.8747, Val Acc: 0.8822, Test Acc: 0.8999\n",
      "Epoch: 018, Train: 0.8799, Val Acc: 0.8807, Test Acc: 0.8982\n",
      "Epoch: 019, Train: 0.8753, Val Acc: 0.8822, Test Acc: 0.8997\n",
      "Epoch: 020, Train: 0.8995, Val Acc: 0.8829, Test Acc: 0.8951\n",
      "Epoch: 021, Train: 0.9065, Val Acc: 0.8793, Test Acc: 0.8897\n",
      "Epoch: 022, Train: 0.9203, Val Acc: 0.8822, Test Acc: 0.8875\n",
      "Epoch: 023, Train: 0.9279, Val Acc: 0.8778, Test Acc: 0.8909\n",
      "Epoch: 024, Train: 0.9227, Val Acc: 0.8749, Test Acc: 0.8934\n",
      "Epoch: 025, Train: 0.9319, Val Acc: 0.8822, Test Acc: 0.8931\n",
      "Epoch: 026, Train: 0.9401, Val Acc: 0.8764, Test Acc: 0.8846\n",
      "Epoch: 027, Train: 0.9413, Val Acc: 0.8640, Test Acc: 0.8723\n",
      "Epoch: 028, Train: 0.9427, Val Acc: 0.8662, Test Acc: 0.8732\n",
      "Epoch: 029, Train: 0.9446, Val Acc: 0.8698, Test Acc: 0.8781\n",
      "Epoch: 030, Train: 0.9468, Val Acc: 0.8778, Test Acc: 0.8926\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.ops import MLP\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GATNetwork(nn.Module):\n",
    "    def __init__(self, heads):\n",
    "        super(GATNetwork, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels=data.num_features, out_channels=64, heads=heads[0])\n",
    "        self.gat2 = GATConv(in_channels=64 * heads[0], out_channels=128, heads=heads[1], concat=False)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.mlp1 = MLP(in_channels=128, hidden_channels=[64, dataset.num_classes], norm_layer=nn.BatchNorm1d)\n",
    "        self.skip = nn.Sequential(nn.Linear(64 * heads[0], 128), nn.ReLU())\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        x = self.bn1(self.gat1(x, edge_index))\n",
    "        x = F.elu(x)\n",
    "        x = self.skip(x) + self.bn2(self.gat2(x, edge_index))\n",
    "        x = self.mlp1(x)\n",
    "        return x\n",
    "\n",
    "model = GATNetwork(heads=[4, 2])\n",
    "\n",
    "cluster_data = ClusterData(data, num_parts=128)\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "\n",
    "      for sub_data in train_loader: \n",
    "          batch = Data(x=sub_data.x, edge_index=sub_data.edge_index)\n",
    "          out = model(batch)  \n",
    "          loss = criterion(out[sub_data.train_mask], sub_data.y[sub_data.train_mask]) \n",
    "          loss.backward()  \n",
    "          optimizer.step()  \n",
    "          optimizer.zero_grad()  \n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data)\n",
    "      pred = out.argmax(dim=1) \n",
    "      \n",
    "      accs = []\n",
    "      for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "          correct = pred[mask] == data.y[mask] \n",
    "          accs.append(int(correct.sum()) / int(mask.sum())) \n",
    "      return accs\n",
    "\n",
    "best_val_acc = 0\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    if counter == patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
